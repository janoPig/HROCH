{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janoPig/HROCH/blob/main/examples/Symbolic_Regression_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfHo92A-k04f"
      },
      "source": [
        "# Symbolic Regression Demo\n",
        "\n",
        "\n",
        "1.   Setup\n",
        "2.   Basic example ground-truth problem\n",
        "3.   Basic example blackbox problem\n",
        "4.   Use feature importances from bbox model\n",
        "5.   Custom instructions set\n",
        "6.   Simple binary clasification with lt/gt\n",
        "7.   Fuzzy regression\n",
        "8.   Classification with fuzzy logic - parity dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hCdk83lCdB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjQmvQuXkri6",
        "outputId": "ae72b63c-0a51-40f7-efde-f60045d8f464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting HROCH\n",
            "  Downloading HROCH-1.2.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from HROCH) (1.21.6)\n",
            "Installing collected packages: HROCH\n",
            "Successfully installed HROCH-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/EpistasisLab/pmlb\n",
            "  Cloning https://github.com/EpistasisLab/pmlb to /tmp/pip-req-build-o17w6kda\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/EpistasisLab/pmlb /tmp/pip-req-build-o17w6kda\n",
            "  Resolved https://github.com/EpistasisLab/pmlb to commit 8df469eb67d139d3f2ce4418e6fb7cf10ccbf84e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from pmlb==1.0.2a0) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from pmlb==1.0.2a0) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from pmlb==1.0.2a0) (6.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.8/dist-packages (from pmlb==1.0.2a0) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->pmlb==1.0.2a0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->pmlb==1.0.2a0) (2022.7)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->pmlb==1.0.2a0) (1.21.6)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.24.0->pmlb==1.0.2a0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.24.0->pmlb==1.0.2a0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.24.0->pmlb==1.0.2a0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.24.0->pmlb==1.0.2a0) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.0->pmlb==1.0.2a0) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.0->pmlb==1.0.2a0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.0->pmlb==1.0.2a0) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.5->pmlb==1.0.2a0) (1.15.0)\n",
            "Building wheels for collected packages: pmlb\n",
            "  Building wheel for pmlb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pmlb: filename=pmlb-1.0.2a0-py3-none-any.whl size=22355 sha256=90bc45631b332d13282b494f152cfeecf30b023a1b04748fd17e7e54e7936f9a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e2ylpt6v/wheels/7d/0f/08/c9721a855c88e115dafc2d2aed942c12baff60be46dc364476\n",
            "Successfully built pmlb\n",
            "Installing collected packages: pmlb\n",
            "Successfully installed pmlb-1.0.2a0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U HROCH\n",
        "#Penn Machine Learning Benchmarks\n",
        "%pip install -U git+https://github.com/EpistasisLab/pmlb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AznY3VNeQFSz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sympy as sp\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pmlb import fetch_data\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from HROCH import SymbolicRegressor, FuzzyRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee5NoEe9lGne"
      },
      "source": [
        "## Basic example ground-truth problem\n",
        "\n",
        "feynman_III_7_38 dataset from pmlb\n",
        "\n",
        "Formula: omega = 2 * mom * B/(h/(2 * pi))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0vMmz_HunNSU"
      },
      "outputs": [],
      "source": [
        "def get_eq(X : pd.DataFrame, expr : str):\n",
        "    model_str = str(sp.parse_expr(expr))\n",
        "    mapping = {'x'+str(i+1): k for i, k in enumerate(X.columns)}\n",
        "    new_model = model_str\n",
        "    for k, v in reversed(mapping.items()):\n",
        "        new_model = new_model.replace(k, v)\n",
        "\n",
        "    return new_model\n",
        "\n",
        "dataset = fetch_data('feynman_III_7_38')\n",
        "Y = np.ravel(pd.DataFrame(dataset, columns=['target']).to_numpy())\n",
        "X = dataset.drop(columns=['target'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), Y, train_size=0.75, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIQoCbUSPl1Y",
        "outputId": "c21ea2e8-3980-4d1e-e0c8-5f508ca6ec01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: r2=0.9999999999999873 rms=4.039649995870836e-06 test: r2=0.9999999999999877 rms=4.028888405992124e-06\n",
            "eq: 12.5663709640502929688*mom*B/h\n"
          ]
        }
      ],
      "source": [
        "reg = SymbolicRegressor(num_threads=1, time_limit = 0.0, iter_limit=1000000, random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "yp_train = reg.predict(X_train)\n",
        "r2_train = r2_score(y_train, yp_train)\n",
        "rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "\n",
        "yp = reg.predict(X_test)\n",
        "r2 = r2_score(y_test, yp)\n",
        "rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "\n",
        "print(f'train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')\n",
        "print(f'eq: {get_eq(X, reg.sexpr)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ_88E-SsCtS"
      },
      "source": [
        "## Basic example blackbox problem\n",
        "\n",
        "588_fri_c4_1000_100 dataset from pmlb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Uu2fbEfH0bwP"
      },
      "outputs": [],
      "source": [
        "dataset = fetch_data('588_fri_c4_1000_100')\n",
        "Y = np.ravel(pd.DataFrame(dataset, columns=['target']).to_numpy())\n",
        "X = dataset.drop(columns=['target'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), Y, train_size=0.75, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dar89dwOsJJ8",
        "outputId": "a56922b5-c98b-452f-c8bd-7896a5f94b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SymbolicSolver train: r2=0.6705863184329303 rms=0.5724199024786217 test: r2=0.5941229429930125 rms=0.6408433039138661\n",
            "eq: 0.58182519674301147461*(oz2*(oz1 + oz5) - 2.91932797431945800781)*sin(oz2)\n"
          ]
        }
      ],
      "source": [
        "reg = SymbolicRegressor(num_threads=1, time_limit = 0.0, iter_limit=1000000, random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "yp_train = reg.predict(X_train)\n",
        "r2_train = r2_score(y_train, yp_train)\n",
        "rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "\n",
        "yp = reg.predict(X_test)\n",
        "r2 = r2_score(y_test, yp)\n",
        "rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "\n",
        "print(f'SymbolicRegressor train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')\n",
        "print(f'eq: {get_eq(X, reg.sexpr)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge9AaopEwTPu"
      },
      "source": [
        "## Use feature importances from bbox model\n",
        "\n",
        "For example, we can use the feature importances from RandomForestRegressor to try to speed up the search process. During mutation, the SymbolicSolver will select the most important features with higher probability. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiw4EoyfwSMP",
        "outputId": "5576844a-e61a-4d3b-c0c7-9efc16a0c6ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestRegressor train: r2=0.9830541104179017 rms=0.12983031029807188 test: r2=0.8303892163473732 rms=0.4142679448325175\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "yp_train = rf.predict(X_train)\n",
        "r2_train = r2_score(y_train, yp_train)\n",
        "rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "\n",
        "yp = rf.predict(X_test)\n",
        "r2 = r2_score(y_test, yp)\n",
        "rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "\n",
        "print(f'RandomForestRegressor train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3anyqvt3w2_s",
        "outputId": "71339a79-0945-4831-81cc-02d538b05d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SymbolicSolver train: r2=0.743787720763619 rms=0.504828516226028 test: r2=0.7067059821487739 rms=0.5447612427637081\n",
            "eq: -0.81791335344314575195*oz2 + 0.81791335344314575195*oz5 - 0.81791335344314575195*sin(oz1 + 1.9202204843009088797*oz2 - 0.52077353000640869141)\n"
          ]
        }
      ],
      "source": [
        "probs = np.power(rf.feature_importances_, 2.0)\n",
        "reg = SymbolicRegressor(num_threads=1, time_limit = 0.0, iter_limit=1000000, random_state=42, feature_probs=probs)\n",
        "\n",
        "reg.fit(X_train, y_train)\n",
        "yp_train = reg.predict(X_train)\n",
        "r2_train = r2_score(y_train, yp_train)\n",
        "rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "\n",
        "yp = reg.predict(X_test)\n",
        "r2 = r2_score(y_test, yp)\n",
        "rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "\n",
        "print(f'SymbolicRegressor train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')\n",
        "print(f'eq: {get_eq(X, reg.sexpr)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQT-z6Bc2zVQ"
      },
      "source": [
        "## Custom instructions set\n",
        "\n",
        "Limit the search to specific mathematical operations. Each math instruction has a defined probability used by the mutation operator.\n",
        "\n",
        "|**Supported instructions**||\n",
        "| ----------- | ----------- |\n",
        "|**math**|add, sub, mul, div, inv, minv, sq2, pow, exp, log, sqrt, cbrt, aq|\n",
        "|**goniometric**|sin, cos, tan, asin, acos, atan, sinh, cosh, tanh|\n",
        "|**other**|nop, max, min, abs, floor, ceil, lt, gt, lte, gte|\n",
        "|**fuzzy**|f_and, f_or, f_xor, f_impl, f_not, f_nand, f_nor, f_nxor, f_nimpl|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFzzaq-H23Bd",
        "outputId": "c720e59b-e108-4d4c-b306-3cf74605764e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: r2=0.8826225841667946 rms=0.34169307794085274 test: r2=0.8569455124038241 rms=0.38045679277078087\n",
            "eq: 0.43304610252380371094*oz4 + (0.5332279205322265625*oz2 + 1.15445457330451972666)*sin(oz1*(0.5332279205322265625*oz2 + 1.15445457330451972666) + 1.17703820286578775267*oz2 + 2.54832330403152253522)\n"
          ]
        }
      ],
      "source": [
        "instr_set={'add': 1.0, 'mul': 1.0, 'div':0.01, 'sin':0.1}\n",
        "reg = SymbolicRegressor(num_threads=1, time_limit = 0.0, iter_limit=1000000, random_state=42, feature_probs=probs, problem=instr_set)\n",
        "\n",
        "reg.fit(X_train, y_train)\n",
        "yp_train = reg.predict(X_train)\n",
        "r2_train = r2_score(y_train, yp_train)\n",
        "rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "\n",
        "yp = reg.predict(X_test)\n",
        "r2 = r2_score(y_test, yp)\n",
        "rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "\n",
        "print(f'train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')\n",
        "print(f'eq: {get_eq(X, reg.sexpr)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0jVDHNk4hUl"
      },
      "source": [
        "## Simple binary clasification with lt/gt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzyiCoks4kBR",
        "outputId": "ad426ee4-6ec4-48c3-f057-74c12d1fa1be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier: mse= 0.025 r2= 0.820287396395684\n",
            "SymbolicSolver: mse= 0.0 r2= 1.0 eq= (x2<(((0.48635864257812500000)*x1)*(((0.20170973241329193115)*x1)+((0.48635864257812500000)*x1))))\n",
            " \n"
          ]
        }
      ],
      "source": [
        "X = np.random.normal(loc=0.0, scale=10.0, size=(4000, 100))\n",
        "y = (0.5*X[:, 0]**2 >= 1.5*X[:, 1])*1.0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=42)\n",
        "\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(X_train, y_train)\n",
        "y_predicted = dtc.predict(X_test)\n",
        "test_mse = mean_squared_error(y_predicted, y_test)\n",
        "test_r2 = r2_score(y_predicted, y_test)\n",
        "print(f'DecisionTreeClassifier: mse= {test_mse} r2= {test_r2}')\n",
        "\n",
        "probs = np.power(dtc.feature_importances_, 2.0)\n",
        "instr_set={'add': 1.0, 'sub': 1.0, 'mul': 1.0, 'lt':0.1, 'gt':0.1, 'lte':0.1, 'gte':0.1}\n",
        "reg = SymbolicRegressor(num_threads=1, time_limit = 0.0, iter_limit=10000000, random_state=42,feature_probs=probs, problem=instr_set)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "y_predicted = reg.predict(X_test)\n",
        "y_predicted = (y_predicted > 0.5)*1.0\n",
        "test_mse = mean_squared_error(y_predicted, y_test)\n",
        "test_r2 = r2_score(y_predicted, y_test)\n",
        "\n",
        "print(f'SymbolicRegressor: mse= {test_mse} r2= {test_r2} eq= {str(reg.sexpr)} ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUGYy8869FWF"
      },
      "source": [
        "## Fuzzy regression\n",
        "\n",
        "Let's create a data set with 40 elements and satisfying the equation\n",
        "y = ((X1 & X16) | (!X4 & X19)) & (X23 | X26)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_2KFzNyD9NiI"
      },
      "outputs": [],
      "source": [
        "X = np.random.uniform(low=0.0, high=1.0, size=(4000, 40))\n",
        "A = X[:, 0] * X[:, 15]\n",
        "B = (1.0 - X[:, 3]) * X[:, 18]\n",
        "C = A + B - A * B  # A or b\n",
        "D = X[:, 22] + X[:, 25] - X[:, 22] * X[:, 25]\n",
        "y = C * D\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGddiI2F9Rxz"
      },
      "source": [
        "Try run FuzzyRegressor find correct equation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0uEMf3H9Tq0",
        "outputId": "ac980472-3da2-4d9a-b888-3105da477a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTreeRegressor: mse= 0.009946199247965297 r2= 0.7639461168623853\n",
            "SymbolicSolver: mse= 7.778538647218386e-16 r2= 0.9999999999999818 eq= (((x19&(!x4))|(((((0.00030057126423344016)&x29)&((x19&(!x4))&((0.00030057126423344016)&x29)))^x1)&x16))&(x26|x23))\n",
            " \n"
          ]
        }
      ],
      "source": [
        "reg = DecisionTreeRegressor()\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "y_predicted = reg.predict(X_test)\n",
        "test_mse = mean_squared_error(y_predicted, y_test)\n",
        "test_r2 = r2_score(y_predicted, y_test)\n",
        "\n",
        "print(f'DecisionTreeRegressor: mse= {test_mse} r2= {test_r2}')\n",
        "\n",
        "probs = np.power(reg.feature_importances_, 2.0)\n",
        "\n",
        "reg = FuzzyRegressor(num_threads=1, time_limit=0.0, iter_limit=20000000, random_state=42, problem='fuzzy')\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "y_predicted = reg.predict(X_test)\n",
        "test_mse = mean_squared_error(y_predicted, y_test)\n",
        "test_r2 = r2_score(y_predicted, y_test)\n",
        "\n",
        "print(f'FuzzyRegressor: mse= {test_mse} r2= {test_r2} eq= {str(reg.sexpr)} ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC4azOpR_aBe"
      },
      "source": [
        "## Classification with fuzzy logic - parity dataset\n",
        "\n",
        "A good simple example is the parity5 and parity5+5 dataset from pmlb. \n",
        "FuzzyRegressor will find equations (((x5^(x4^x3))^x1)^x2) or similar that can be simplified to this form. The equation Xor fits the parity calculation perfectly. The DecisionTreeClassifier and RandomForestClassifier fit the training data with an r2 score of 1.0, but absolutely not the test data.\n",
        "\n",
        "Because the parity5 dataset is very small we repeat the experiment 10 times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HflsMpbP_WU8",
        "outputId": "ba7fbdb0-babf-43bd-8373-bd0444a6612d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SymbolicSolver\n",
            "====================\n",
            "parity5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((0.00000000000000000000)|(x2^((x5|x5)^(x4^(x1^x3)))))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((x4^x2)^(x5^((0.00000000000000000000)|((x1&x1)^x3))))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((x2&x2)^(((x1&x1)^x3)^(x5^x4)))&((x2&x2)^(((x1&x1)^x3)^(x5^x4))))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (x4^(x5^(x3^(x1^x2))))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (!((x5^(x4&x4))^((x2^(!x3))^x1)))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((x5^(x4^x3))^x1)^x2)\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (x2^(((x3^x1)^(x4^x5))|((x3^x1)^(x4^x5))))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (x5^((x4&(!(!x4)))^(x3^(x2^x1))))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((x3^(x4^x2))^((0.00000000000000000000)|x1))^x5)\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((0.00000000000000000000)|x1)^(x4^((x3^x2)^x5)))\n",
            "\n",
            "parity5+5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((!x3)^(!(!(x10^x10))))^((!((x4^(x8^x6))^x2))|(0.00000000000000000000)))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((1.00000000000000000000)&x6)^((x3^(!(x4^(!x8))))^(x2&x2)))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (!(((!(x2^x6))^x4)^((!x3)^((1.00000000000000000000)^((!x8)^(((((!x3)&(!x3))^x3)|(((!x3)&(!x3))^x3))|(-0.22080147266387939453)))))))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (x4^((((!x2)^x6)|((0.00003336164445499890)&(0.00003336164445499890)))^(!((!(!x3))^x8))))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((!((x10^x2)^x8))^x4)^((1.00000000000000000000)^((x6^x3)^x10)))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (x8^((1.00000000000000000000)^(((!x3)^(x2^x4))^x6)))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((!(((x6|((x6^x8)|((x6^x8)&x9)))|(x2^(x3^((x6^x8)|((x6^x8)&x9)))))&(x2^(x3^((x6^x8)|((x6^x8)&x9))))))^(!(x4&(1.00000000000000000000))))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((!(!x3))^((((x2^x8)^x6)^x4)&(((x2^x8)^x6)^x4)))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (x3^((!x4)^(((x6^x8)^(x7|((!x7)|(!x4))))^((!((0.00000000000000000000)&(0.00000000000000000000)))&(((0.00000000000000000000)&(0.00000000000000000000))|x2)))))\n",
            "\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (x4^((x2^x8)^((x5&(x3^x6))|((x3^x6)|((x3^x6)&(x3^x6))))))\n",
            "\n",
            "DecisionTreeClassifier\n",
            "====================\n",
            "parity5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.0 rms=0.8660254037844386\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.5 rms=0.9354143466934853\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.5 rms=0.9354143466934853\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.7333333333333334 rms=0.9354143466934853\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.7333333333333334 rms=0.9354143466934853\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.5 rms=0.9354143466934853\n",
            "parity5+5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=0.27246420956442274 rms=0.42602190310089477\n",
            "train: r2=1.0 rms=0.0 test: r2=0.31650957737914254 rms=0.4133019541909744\n",
            "train: r2=1.0 rms=0.0 test: r2=0.08907070083359059 rms=0.4734968724883278\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.9567844342037892 rms=0.6956908545644072\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.6227963525835867 rms=0.6369410884673212\n",
            "train: r2=1.0 rms=0.0 test: r2=0.1022819472616634 rms=0.4734968724883278\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.12570993914807294 rms=0.5302252257631536\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.8106037544393707 rms=0.6722776921582818\n",
            "train: r2=1.0 rms=0.0 test: r2=0.2269994905756494 rms=0.4383729217291347\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.42238470191226085 rms=0.5935597419466607\n",
            "RandomForestClassifier\n",
            "====================\n",
            "parity5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.666666666666667 rms=0.9354143466934853\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.0 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.0 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.5 rms=0.9354143466934853\n",
            "parity5+5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.3980099502487562 rms=0.5905543568534369\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.4666565318739233 rms=0.60543211238307\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.532674693835546 rms=0.6141858019266289\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.8272913466461855 rms=0.6722776921582818\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.6227963525835867 rms=0.6369410884673212\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.7811866125760647 rms=0.6669631606402602\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.6814401622718051 rms=0.6480191552900082\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.767833587011669 rms=0.6642899508422776\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.1738155883851249 rms=0.5401989879842585\n",
            "train: r2=1.0 rms=0.0 test: r2=-1.054555680539932 rms=0.7133700282132863\n"
          ]
        }
      ],
      "source": [
        "datasets = [(fetch_data('parity5'), 'parity5'), (fetch_data('parity5+5'), 'parity5+5')]\n",
        "random_states = [42, 1083, 20133, 35879, 45688, 211565, 1212248, 58985945, 48994485, 5454544]\n",
        "classifiers = {FuzzyRegressor: {'problem':'fuzzy', 'iter_limit':5000000, 'num_threads':1}, DecisionTreeClassifier: {}, RandomForestClassifier: {}}\n",
        "\n",
        "for classifier, params in classifiers.items():\n",
        "  print(classifier.__name__)\n",
        "  print('='*20)\n",
        "  for dataset, dataset_name in datasets:\n",
        "    print(dataset_name)\n",
        "    print('-'*20)\n",
        "    Y = np.ravel(pd.DataFrame(dataset, columns=['target']).to_numpy())\n",
        "    X = dataset.drop(columns=['target']).to_numpy()\n",
        "    for rs in random_states:\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.75, test_size=0.25, random_state=rs)\n",
        "      clf = classifier(random_state=rs, **params)\n",
        "      clf.fit(X_train, y_train)\n",
        "      yp_train = clf.predict(X_train)\n",
        "      if classifier is FuzzyRegressor:\n",
        "        yp_train = (yp_train > 0.5)*1.0\n",
        "      r2_train = r2_score(y_train, yp_train)\n",
        "      rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "      yp = clf.predict(X_test)\n",
        "      if classifier is FuzzyRegressor:\n",
        "        yp = (yp > 0.5)*1.0\n",
        "      r2 = r2_score(y_test, yp)\n",
        "      rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "      print(f'train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')\n",
        "      if classifier is FuzzyRegressor:\n",
        "        print(f'eq: {clf.sexpr}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNgX5Xv97y5JbKI3hLoMom3",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
