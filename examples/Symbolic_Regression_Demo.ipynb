{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janoPig/HROCH/blob/main/examples/Symbolic_Regression_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfHo92A-k04f"
      },
      "source": [
        "# Symbolic Regression Demo\n",
        "\n",
        "\n",
        "1.   Setup\n",
        "2.   Basic example ground-truth problem\n",
        "3.   Basic example blackbox problem\n",
        "4.   Use feature importances from bbox model\n",
        "5.   Custom instructions set\n",
        "6.   Simple binary clasification with lt/gt\n",
        "7.   Fuzzy regression\n",
        "8.   Classification with fuzzy logic - parity dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hCdk83lCdB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjQmvQuXkri6",
        "outputId": "ae72b63c-0a51-40f7-efde-f60045d8f464"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U HROCH\n",
        "#Penn Machine Learning Benchmarks\n",
        "%pip install -U git+https://github.com/EpistasisLab/pmlb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "AznY3VNeQFSz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sympy as sp\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pmlb import fetch_data\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from HROCH import SymbolicRegressor, FuzzyRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee5NoEe9lGne"
      },
      "source": [
        "## Basic example ground-truth problem\n",
        "\n",
        "feynman_III_7_38 dataset from pmlb\n",
        "\n",
        "Formula: omega = 2 * mom * B/(h/(2 * pi))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "0vMmz_HunNSU"
      },
      "outputs": [],
      "source": [
        "def get_eq(X : pd.DataFrame, expr : str):\n",
        "    model_str = str(sp.parse_expr(expr))\n",
        "    mapping = {'x'+str(i+1): k for i, k in enumerate(X.columns)}\n",
        "    new_model = model_str\n",
        "    for k, v in reversed(mapping.items()):\n",
        "        new_model = new_model.replace(k, v)\n",
        "\n",
        "    return new_model\n",
        "\n",
        "dataset = fetch_data('feynman_III_7_38')\n",
        "Y = np.ravel(pd.DataFrame(dataset, columns=['target']).to_numpy())\n",
        "X = dataset.drop(columns=['target'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), Y, train_size=0.75, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIQoCbUSPl1Y",
        "outputId": "c21ea2e8-3980-4d1e-e0c8-5f508ca6ec01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: r2=0.999999999999998 rms=1.6125012744918447e-06 test: r2=0.999999999999998 rms=1.6204839497481079e-06\n",
            "eq: 12.566370964050293*x0*mom/B\n"
          ]
        }
      ],
      "source": [
        "reg = SymbolicRegressor(num_threads=1, time_limit = 0.0, iter_limit=100000, random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "yp_train = reg.predict(X_train)\n",
        "r2_train = r2_score(y_train, yp_train)\n",
        "rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "\n",
        "yp = reg.predict(X_test)\n",
        "r2 = r2_score(y_test, yp)\n",
        "rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "\n",
        "print(f'train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')\n",
        "print(f'eq: {get_eq(X, reg.sexpr_)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ_88E-SsCtS"
      },
      "source": [
        "## Basic example blackbox problem\n",
        "\n",
        "588_fri_c4_1000_100 dataset from pmlb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Uu2fbEfH0bwP"
      },
      "outputs": [],
      "source": [
        "dataset = fetch_data('588_fri_c4_1000_100')\n",
        "Y = np.ravel(pd.DataFrame(dataset, columns=['target']).to_numpy())\n",
        "X = dataset.drop(columns=['target'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), Y, train_size=0.75, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dar89dwOsJJ8",
        "outputId": "a56922b5-c98b-452f-c8bd-7896a5f94b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SymbolicRegressor train: r2=0.7569770202772456 rms=0.49166305989611125 test: r2=0.6983115730729911 rms=0.552502089377683\n",
            "eq: 0.3931830823421478*oz3 + 0.3931830823421478*(x0 + 2.346113681793213)*(0.12121981414771422*oz2*oz4 - sin(2.176326115047859*oz1))\n"
          ]
        }
      ],
      "source": [
        "reg = SymbolicRegressor(num_threads=1, time_limit = 0.0, iter_limit=100000, random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "yp_train = reg.predict(X_train)\n",
        "r2_train = r2_score(y_train, yp_train)\n",
        "rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "\n",
        "yp = reg.predict(X_test)\n",
        "r2 = r2_score(y_test, yp)\n",
        "rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "\n",
        "print(f'SymbolicRegressor train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')\n",
        "print(f'eq: {get_eq(X, reg.sexpr_)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge9AaopEwTPu"
      },
      "source": [
        "## Use feature importances from bbox model\n",
        "\n",
        "For example, we can use the feature importances from RandomForestRegressor to try to speed up the search process. During mutation, the SymbolicSolver will select the most important features with higher probability. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiw4EoyfwSMP",
        "outputId": "5576844a-e61a-4d3b-c0c7-9efc16a0c6ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestRegressor train: r2=0.9830541104179017 rms=0.12983031029807188 test: r2=0.8303892163473732 rms=0.4142679448325175\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "yp_train = rf.predict(X_train)\n",
        "r2_train = r2_score(y_train, yp_train)\n",
        "rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "\n",
        "yp = rf.predict(X_test)\n",
        "r2 = r2_score(y_test, yp)\n",
        "rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "\n",
        "print(f'RandomForestRegressor train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3anyqvt3w2_s",
        "outputId": "71339a79-0945-4831-81cc-02d538b05d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SymbolicRegressor train: r2=0.8919199732812224 rms=0.3278812866387748 test: r2=0.8700743468791842 rms=0.3625785048723392\n",
            "eq: 0.2813378870487213*oz3 + 0.3380877375602722*oz4 - 0.2813378870487213*(x0 + oz1)*(sin(x0 + oz1)**2 - 0.5105604529380798) - sin(x0 + oz1)**2 - sin(x0 + oz1) + 0.5105604529380798\n"
          ]
        }
      ],
      "source": [
        "probs = np.power(rf.feature_importances_, 2.0)\n",
        "reg = SymbolicRegressor(num_threads=1, time_limit = 0.0, iter_limit=100000, random_state=42, feature_probs=probs)\n",
        "\n",
        "reg.fit(X_train, y_train)\n",
        "yp_train = reg.predict(X_train)\n",
        "r2_train = r2_score(y_train, yp_train)\n",
        "rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "\n",
        "yp = reg.predict(X_test)\n",
        "r2 = r2_score(y_test, yp)\n",
        "rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "\n",
        "print(f'SymbolicRegressor train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')\n",
        "print(f'eq: {get_eq(X, reg.sexpr_)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQT-z6Bc2zVQ"
      },
      "source": [
        "## Custom instructions set\n",
        "\n",
        "Limit the search to specific mathematical operations. Each math instruction has a defined probability used by the mutation operator.\n",
        "\n",
        "|**Supported instructions**||\n",
        "| ----------- | ----------- |\n",
        "|**math**|add, sub, mul, div, inv, minv, sq2, pow, exp, log, sqrt, cbrt, aq|\n",
        "|**goniometric**|sin, cos, tan, asin, acos, atan, sinh, cosh, tanh|\n",
        "|**other**|nop, max, min, abs, floor, ceil, lt, gt, lte, gte|\n",
        "|**fuzzy**|f_and, f_or, f_xor, f_impl, f_not, f_nand, f_nor, f_nxor, f_nimpl|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFzzaq-H23Bd",
        "outputId": "c720e59b-e108-4d4c-b306-3cf74605764e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: r2=0.7719326794473848 rms=0.47629436022682353 test: r2=0.7184290551818527 rms=0.5337630650788203\n",
            "eq: 0.9881536364555359*(0.26769205927848816*oz1*(x0 + oz4 + 0.10410416126251221) - 0.80549142255765815)*(x0 + sin(2*oz1) + sin(oz1*(x0 + 0.10410416126251221)))\n"
          ]
        }
      ],
      "source": [
        "instr_set={'add': 1.0, 'mul': 1.0, 'div':0.01, 'sin':0.1}\n",
        "reg = SymbolicRegressor(num_threads=1, time_limit = 0.0, iter_limit=100000, random_state=42, feature_probs=probs, problem=instr_set)\n",
        "\n",
        "reg.fit(X_train, y_train)\n",
        "yp_train = reg.predict(X_train)\n",
        "r2_train = r2_score(y_train, yp_train)\n",
        "rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "\n",
        "yp = reg.predict(X_test)\n",
        "r2 = r2_score(y_test, yp)\n",
        "rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "\n",
        "print(f'train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')\n",
        "print(f'eq: {get_eq(X, reg.sexpr_)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0jVDHNk4hUl"
      },
      "source": [
        "## Simple binary clasification with lt/gt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzyiCoks4kBR",
        "outputId": "ad426ee4-6ec4-48c3-f057-74c12d1fa1be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier: mse= 0.022 r2= 0.8528536361873039\n",
            "SymbolicRegressor: mse= 0.0 r2= 1.0 eq= (((-0.5468273758888245)+(x0*x0))>((x1-0.5520243644714355)+(x1+x1))) \n"
          ]
        }
      ],
      "source": [
        "X = np.random.normal(loc=0.0, scale=10.0, size=(4000, 100))\n",
        "y = (0.5*X[:, 0]**2 >= 1.5*X[:, 1])*1.0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=42)\n",
        "\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(X_train, y_train)\n",
        "y_predicted = dtc.predict(X_test)\n",
        "test_mse = mean_squared_error(y_predicted, y_test)\n",
        "test_r2 = r2_score(y_predicted, y_test)\n",
        "print(f'DecisionTreeClassifier: mse= {test_mse} r2= {test_r2}')\n",
        "\n",
        "probs = np.power(dtc.feature_importances_, 2.0)\n",
        "instr_set={'add': 1.0, 'sub': 1.0, 'mul': 1.0, 'lt':0.1, 'gt':0.1, 'lte':0.1, 'gte':0.1}\n",
        "reg = SymbolicRegressor(num_threads=1, time_limit = 0.0, iter_limit=100000, random_state=42,feature_probs=probs, problem=instr_set)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "y_predicted = reg.predict(X_test)\n",
        "y_predicted = (y_predicted > 0.5)*1.0\n",
        "test_mse = mean_squared_error(y_predicted, y_test)\n",
        "test_r2 = r2_score(y_predicted, y_test)\n",
        "\n",
        "print(f'SymbolicRegressor: mse= {test_mse} r2= {test_r2} eq= {str(reg.sexpr_)} ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC4azOpR_aBe"
      },
      "source": [
        "## Classification with fuzzy logic - parity dataset\n",
        "\n",
        "A good simple example is the parity5 and parity5+5 dataset from pmlb. \n",
        "FuzzyRegressor will find equations (((x5^(x4^x3))^x1)^x2) or similar that can be simplified to this form. The equation Xor fits the parity calculation perfectly. The DecisionTreeClassifier and RandomForestClassifier fit the training data with an r2 score of 1.0, but absolutely not the test data.\n",
        "\n",
        "Because the parity5 dataset is very small we repeat the experiment 10 times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HflsMpbP_WU8",
        "outputId": "ba7fbdb0-babf-43bd-8373-bd0444a6612d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FuzzyRegressor\n",
            "====================\n",
            "parity5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=-1.6666666666666665 rms=0.7071067811865476\n",
            "eq: (((x0&x2)^(~(x4^(x1^x3))))|(~(x2|x0)))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((x0^(((x3^x2)^x1)&((x3^x2)^x1)))^(x4&x4))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((0.0052818614058196545|(~(x1&(~x1))))^((~(x1&(~x1)))^((~((~x1)))^((x4^x2)^(~(~(x3^x0)))))))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((~((~((x1^x0)^x2))^x3))^x4)\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((x3^x2)^((x4^x1)&(x4^x1)))^x0)\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (~((1.0&(((~x2)&(~x2))^(x3^x0)))^(x4^x1)))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((x4^(~((x0|x0)|(x0|x0))))^((((~x3)|(0.9993218183517456|x2))|x1)&(x2^((~x3)^x1))))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (~(1.0&((x2^(~(x1^(x3^x0))))^(((x1^(x3^x0))&(~(x1^(x3^x0))))|x4))))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((x2^((((x3|x4)&x4)^x3)^x1))^x0)\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((x2^(x1^x4))|(x2^(x1^x4)))^((x0&x0)^x3))\n",
            "parity5+5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (~(~(x1^(x3^((~x5)^(~(x7^x2)))))))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (~(((x1^x2)^(1.0|x6))^(((x7^x5)&(x7^x5))^x3)))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((((x5^((x2^x7)|(x2^x7)))^(((x2^x7)^(~((x2^x7)|(x2^x7))))&(~x1)))&((x3&(0.3617982566356659&((x2^x7)|(~x8))))|1.0))^1.0)^(~(~x3)))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (x2^((x3^(x5&((x2|1.0)|(x2|1.0))))^((x4|(x2|1.0))&((x1&(x2|1.0))^x7))))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((x2^x7)^x3)^((x5^x1)|(0.00037949648685753345&0.00037949648685753345)))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((((~(~x5))^x3)^(x7^(x2^((~1.0)|x1))))|(((~(~x5))|x6)&(1.0^(1.0|x6))))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((x5^(~((x3^(~((x2^x1)&(x2|x1))))|(0.0013738548150286078&0.00014546044985763729))))^x7)\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((~((x7^x5)&(x7^x5)))^(~((x3^x1)^x2)))\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: ((((~((x7^x1)^(x3^x2)))^(~1.0))^x5)^1.0)\n",
            "train: r2=1.0 rms=0.0 test: r2=1.0 rms=0.0\n",
            "eq: (((((~(x5^x1))^x3)^(((x5^x1)^x2)^(~(x5^x1))))^(x7&((~(x5^x1))|(x8|(x5^x1)))))^(~(1.0|(x5^x1))))\n",
            "DecisionTreeClassifier\n",
            "====================\n",
            "parity5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.0 rms=0.8660254037844386\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.5 rms=0.9354143466934853\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.5 rms=0.9354143466934853\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.7333333333333334 rms=0.9354143466934853\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.7333333333333334 rms=0.9354143466934853\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.5 rms=0.9354143466934853\n",
            "parity5+5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=0.27246420956442274 rms=0.42602190310089477\n",
            "train: r2=1.0 rms=0.0 test: r2=0.31650957737914254 rms=0.4133019541909744\n",
            "train: r2=1.0 rms=0.0 test: r2=0.08907070083359059 rms=0.4734968724883278\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.9567844342037892 rms=0.6956908545644072\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.6227963525835867 rms=0.6369410884673212\n",
            "train: r2=1.0 rms=0.0 test: r2=0.1022819472616634 rms=0.4734968724883278\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.12570993914807294 rms=0.5302252257631536\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.8106037544393707 rms=0.6722776921582818\n",
            "train: r2=1.0 rms=0.0 test: r2=0.2269994905756494 rms=0.4383729217291347\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.42238470191226085 rms=0.5935597419466607\n",
            "RandomForestClassifier\n",
            "====================\n",
            "parity5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.666666666666667 rms=0.9354143466934853\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.0 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.0 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-3.2666666666666666 rms=1.0\n",
            "train: r2=1.0 rms=0.0 test: r2=-2.5 rms=0.9354143466934853\n",
            "parity5+5\n",
            "--------------------\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.3980099502487562 rms=0.5905543568534369\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.4666565318739233 rms=0.60543211238307\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.532674693835546 rms=0.6141858019266289\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.8272913466461855 rms=0.6722776921582818\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.6227963525835867 rms=0.6369410884673212\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.7811866125760647 rms=0.6669631606402602\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.6814401622718051 rms=0.6480191552900082\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.767833587011669 rms=0.6642899508422776\n",
            "train: r2=1.0 rms=0.0 test: r2=-0.1738155883851249 rms=0.5401989879842585\n",
            "train: r2=1.0 rms=0.0 test: r2=-1.054555680539932 rms=0.7133700282132863\n"
          ]
        }
      ],
      "source": [
        "datasets = [(fetch_data('parity5'), 'parity5'), (fetch_data('parity5+5'), 'parity5+5')]\n",
        "random_states = [42, 1083, 20133, 35879, 45688, 211565, 1212248, 58985945, 48994485, 5454544]\n",
        "classifiers = {FuzzyRegressor: {'iter_limit':100000, 'num_threads':1}, DecisionTreeClassifier: {}, RandomForestClassifier: {}}\n",
        "\n",
        "for classifier, params in classifiers.items():\n",
        "  print(classifier.__name__)\n",
        "  print('='*20)\n",
        "  for dataset, dataset_name in datasets:\n",
        "    print(dataset_name)\n",
        "    print('-'*20)\n",
        "    Y = np.ravel(pd.DataFrame(dataset, columns=['target']).to_numpy())\n",
        "    X = dataset.drop(columns=['target']).to_numpy()\n",
        "    for rs in random_states:\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.75, test_size=0.25, random_state=rs)\n",
        "      clf = classifier(random_state=rs, **params)\n",
        "      clf.fit(X_train, y_train)\n",
        "      yp_train = clf.predict(X_train)\n",
        "      if classifier is FuzzyRegressor:\n",
        "        yp_train = (yp_train > 0.5)*1.0\n",
        "      r2_train = r2_score(y_train, yp_train)\n",
        "      rms_train = np.sqrt(mean_squared_error(y_train, yp_train))\n",
        "      yp = clf.predict(X_test)\n",
        "      if classifier is FuzzyRegressor:\n",
        "        yp = (yp > 0.5)*1.0\n",
        "      r2 = r2_score(y_test, yp)\n",
        "      rms = np.sqrt(mean_squared_error(y_test, yp))\n",
        "      print(f'train: r2={r2_train} rms={rms_train} test: r2={r2} rms={rms}')\n",
        "      if classifier is FuzzyRegressor:\n",
        "        print(f'eq: {clf.sexpr_}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNgX5Xv97y5JbKI3hLoMom3",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
